Person paper files:

[1] Assessment of a Modular Upper-Limb Exoskeleton with Powered Assistance

[2] MultiMAE-DER: Multimodal Masked Autoencoder for Dynamic Emotion Recognition

[3] Emotion Styles Hide in Deep Speaker Embeddings: Disentangle Deep Speaker Embeddings for Speaker Clustering

[4] Human Intention Detection for Upper-Limb Assistive Exoskeletons Using a Motorâ€™s Built-in Current Sensor

[5] CLL-RetICL: Contrastive Linguistic Label Retrieval-based In-Context Learning for Text Classification via Large Language Models

[6] MTCAE-DFER: Multi-Task Cascaded Autoencoder for Dynamic Facial Expression Recognition

[7] Label Ranker: Self-aware Preference for Classification Label Position in Visual Masked Self-supervised Pre-trained Model

[8] Load Estimation for Industrial Load-lifting Exoskeletons Using Insole Pressure Sensors and Machine Learning

[9] Entropy Reveals Block Importance in Masked Self-Supervised Vision Transformers

2024.04
MultiMAE-DER: Multimodal Masked Autoencoder for Dynamic Emotion Recognition
Peihao Xiang, Chaohao Lin, Kaida Wu, Ou Bai
IEEE 14th International Conference on Pattern Recognition Systems
15-18 July, 2024 | University of Westminster, London, UK
[ICPRS 2024] http://s836450039.websitehome.co.uk/icprs24/index.html#intro
[arXiv] https://arxiv.org/abs/2404.18327
[Paper] https://doi.org/10.1109/ICPRS62101.2024.10677820
[Code] https://github.com/Peihao-Xiang/MultiMAE-DER
[Video] https://www.youtube.com/watch?v=HqaTGxtQaEo
